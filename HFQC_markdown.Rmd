---
title: "High Frequency QC"
author: "Elise Hinman"
date: '2022-06-07'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Future ideas
This script is intended to work with discrete datasets originating in an excel spreadsheet. However, it is designed to be adaptable to the high frequency workgroup's development of a more streamlined process for high frequency data upload, storage, and processing. Following a discussion with Chris Shope, we determined that perhaps the QC script will run on newly uploaded data, or on a consistent basis as data populate the system. However, the drift corrections, extreme values, and interpolation of values will necessarily/ideally only occur with new calibration data. When calibration data are populated, these scripts will run.

## Load required packages
The packages below run the programs needed to QC the high frequency dataset.
```{r, packages, message=FALSE}
library(zoo)
library(plotly)
library(leaflet)
library(tidyverse)
```

## Dataset information
The code blocks below are filled in by the user prior to building the RMarkdown QC report. They include site metadata, calibration, and nonreal value information.

### Site metadata
This section contains information on the site location, name, and the water quality parameters measured by the sonde.       
```{r, eval=F, echo=F}
### MANUALLY FILL OUT THE 'meta' CODE BLOCK BELOW

### NOTE Parameters currently supported include: 
### c("Temperature","Specific conductance","pH","DO saturation","DO concentration","Turbidity")

### Each parameter in your dataset should correspond to a column of the same name, with each row in the column filled with parameter values for a given date.
```

```{r,meta}
#================================================================================
filepath = "All_2021_4991820_JORDAN R AT CUDAHY LANE AB S DAVIS S WWTP_Raw.csv"

sitename = "Jordan River at Cudahy Lane above South Davis WWTP"
siteid = "4991820"
lat_long = c(40.842037, -111.951142)

parameters = c("Temperature","Specific conductance","pH","DO saturation","DO concentration","Turbidity")
#================================================================================
```

### Rule for removing zeroes
If the median of the entire raw dataset is above the value provided below, then all zeroes will be flagged as errant and removed. If not, zeroes will be maintained in dataset. Future updates could include median values specific to each parameter.
```{r, zeroes}
#=================================================================================
median_abv = 1
# window = 30
#=================================================================================
```

### Calibration information
This section contains the sonde values and standard values recorded at each calibration event. The current version accommodates two calibration events but can be expanded when needed. Ideally, this process could involve the constant upload of raw data to the database. However, when a calibration point is uploaded, the data are then corrected using calibration specifications and other QC exercises in an automated script for stakeholder consumption.
```{r, eval=F, echo=F}
### MANUALLY FILL OUT THE 'calibration_1' and (if applicable) 'calibration_2' CODE BLOCKS BELOW
### CURRENTLY ACCOMMODATES 1-2 CALIBRATION REPORTS 
### If multiple calibrations performed, enter calibrations in chronological order, with the earlier event entered first.
### Enter in the date, time, calibration standard(s) and sonde readings before/after calibration
### If you do not have calibration reports for certain parameters, comment out the lines using the pound sign (#)
### Cannot calibrate temperature on sondes at this time
```

```{r, calibration_1}
## CALIBRATION 1 SPECS
#===============================================================================
cal_date = "03/24/2021 17:45"

# Specific conductance
spC_val = 1543
spC_cal = 1413

# pH
pH_val = 7.46
pH_cal = 7
pH_val2 = 10.36
pH_cal2 = 10

# Turbidity
turb_val = -2.6
turb_cal = 0

# DO Saturation
DOsat_val = 94
DOsat_cal = 100

# DO Concentration
DOconc_val = NA
DOconc_cal = NA

# Temperature
temp_val = NA
temp_cal = NA
#===============================================================================
cal_values = data.frame(
  Parameter = c("Specific conductance","pH","pH","Turbidity","DO saturation","DO concentration","Temperature"),
  std = c(spC_cal,pH_cal,pH_cal2,turb_cal,DOsat_cal,DOconc_cal,temp_cal),
  val = c(spC_val,pH_val,pH_val2,turb_val,DOsat_val,DOconc_val,temp_val)
)
cal_values = subset(cal_values, !is.na(cal_values$std))
cal_1 = list()
cal_1$date = cal_date
cal_1$std_val = cal_values
rm(spC_cal,pH_cal,pH_cal2,turb_cal,DOsat_cal,DOconc_cal,temp_cal,spC_val,pH_val,pH_val2,turb_val,DOsat_val,DOconc_val,temp_val)
```

```{r, calibration_2}
# ## CALIBRATION 2 SPECS
# #===============================================================================
cal_date = NA # if not NA, un-comment and fill in all lines below
# 
# # Specific conductance
# spC_val = NA
# spC_cal = NA
# 
# # pH
# pH_val = NA
# pH_cal = NA
# 
# # Turbidity
# turb_val = NA
# turb_cal = NA
# 
# # DO Saturation
# DOsat_val = NA
# DOsat_cal = NA
# 
# # DO Concentration
# DOconc_val = NA
# DOconc_cal = NA
# 
# # Temperature
# temp_val = NA
# temp_cal = NA
# #===============================================================================
if(is.na(cal_date)){
  cal_2 = list(date=NA)
}else{
cal_values = data.frame(
Parameter = c("Specific conductance","pH","Turbidity","DO saturation","DO concentration","Temperature"),
std = c(spC_cal,pH_cal,turb_cal,DOsat_cal,DOconc_cal,temp_cal),
val = c(spC_val,pH_val,turb_val,DOsat_val,DOconc_val,temp_val)
)
cal_2 = list()
cal_2$date = cal_date
cal_2$std_val = cal_values}
```

### Nonreal value limits
Each parameter has a realistic range of values recorded by the sonde based on the physical properties of the system. This section allows the user to specify what values are nonreal and should be flagged as erroneous.
```{r, eval=F, echo=F}
### MANUALLY FILL OUT THE 'nonreal' CODE BLOCK BELOW
### Lower and upper limits for nonreal values may be manually adjusted
```

```{r, nonreal}
#================================================================================
Temperature = c(-10,100)
Specific_conductance = c(0, 16000)
pH = c(0,14)
DO_saturation = c(0,500)
DO_conc = c(0,50)
Turbidity = c(0,5000)
#================================================================================
```

### Interpolation specs
There are some missing data points UDWQ is comfortable filling in based on neighboring in values. This section allows the user to specify the time step and maximum allowable number of missing time steps to fill in the values. The current version uses a linear interpolation, but future iterations might specify a different type of interpolation function.
```{r, eval=F, echo=F}
### Manually edit the frequency at which the sonde collects data in minutes (every 15 minutes, every 30 minutes, every hour, etc.)
### Manually specify the max gap allowable to interpolate between two points.
```

```{r, spec_interp}
#================================================================================
frequency = 15
max_gap = 2
#================================================================================
```

## Data upload to long format
The first step is to read in the data from the excel spreadsheet and get the dates into the correct format for use in the rest of the script. This section also creates columns for the parameter name and unit name in preparation of conversion to long format. When the dataset is in a long format, each row represents a unique measurement observation in time. If multiple parameters values were recorded at a single point of time, each parameter value will have its own row.
```{r, longify}
dat = readr::read_csv(filepath,col_names = c("LOCAL_DATETIME","UTC_OFFSET","UTC_DATETIME",parameters), 
                      col_types = c("c","n","c",rep("n",length(parameters))), skip=3)
dat_long = tidyr::pivot_longer(dat, cols = all_of(parameters), names_to = "Parameter")
dat_long$Date = lubridate::mdy_hm(dat_long$UTC_DATETIME)
dat_long = dat_long%>%
  mutate(units = dplyr::recode(Parameter, "Temperature"="dC","Specific conductance"="uS/cm","pH"="None","DO saturation"="%", "DO concentration"="mg/L","Turbidity"="NTU"))%>%rename(value_raw = value)

dat_long$sampID = seq(100000,(nrow(dat_long)+99999), by=1)
head(dat_long)
```
### Map and timeseries
Quick look at the location and raw data. An interactive plotly plot is saved to the working directory with all of the raw data for each parameter.
```{r, map, echo=FALSE}
m = wqTools::baseMap()%>%
  setView(lng=lat_long[2],lat=lat_long[1], zoom=8, options = list())%>%
  addCircleMarkers(lng=lat_long[2],lat=lat_long[1], color="#034963", popup = paste0(
    "Site ID: ", siteid,
    "<br>Site Name: ", sitename,
    "<br>Parameters: ", paste(parameters, collapse=", ")
  ))
m
```

```{r, rawplot, echo=FALSE, message=FALSE,warning=FALSE}
p = plotly::plot_ly(data=dat_long, x=~Date, y=~value_raw, color=~Parameter, type="scatter", mode="lines+markers")
htmlwidgets::saveWidget(p, file = paste0(sitename,"_RawData_Plot.html"))
```

## QC Step 1: Flag suspect zero values
Often, zero values represent sonde malfunctions. Zeroes in the dataset then affect interpolation values. The current suggested method for dealing with possibly erroneous values is to run a simple "if else" script, where if the median of the dataset is above the value specified at the beginning of this document, all zeroes are flagged as questionable and removed from the dataset and the interpolation calculation. At this time, the value is not parameter specific, but certainly could be in a future release.
```{r}
param_meds = dat_long%>%group_by(Parameter)%>%summarise(median = median(value_raw, na.rm = TRUE))
param_rmv = subset(param_meds, param_meds$median>median_abv)$Parameter
dat_long1 = dat_long%>%add_column(value.1 = NA)
dat_long1$value.1 = ifelse(dat_long1$Parameter%in%param_rmv&dat_long1$value_raw==0,NA,dat_long1$value_raw)
dat_long1$zero_note = ifelse(dat_long1$Parameter%in%param_rmv&dat_long1$value_raw==0,"Zero removed from dataset because median is above specified threshold",NA)
```

## QC Step 2: Drift Correction
Document when calibrations were performed on which parameters for use in the drift correction step. Drift correction equations taken from the [driftR package](https://rdrr.io/cran/driftR/f/vignettes/driftR.Rmd), developed by Andrew Shaughnessy, Christopher Prener, and Elizabeth Hasenmueller. EDH recently identified an error in the driftR package equations and brought this to the attention of the developer. It will be updated and corrected in a future version of the package. For now, the script below contains replicated (corrected) equations from the package.

```{r, cal_adjust1, message=FALSE,warning=FALSE, fig.width=12, fig.height=10}
end_datetime1 = lubridate::mdy_hm(cal_1$date)+lubridate::hours(7)

cal_dat = subset(dat_long1, dat_long1$Date<end_datetime1&dat_long1$Parameter%in%cal_1$std_val$Parameter)
cal_dat$numTime = as.numeric(cal_dat$Date)
cal_dat$totTime = max(cal_dat$numTime)-min(cal_dat$numTime)
cal_dat$corrFac = (cal_dat$numTime-min(cal_dat$numTime))/cal_dat$totTime

cal_num = cal_1$std_val%>%group_by(Parameter)%>%mutate(cal_count=length(std))

# Single-point correction
cal_single = subset(cal_num, cal_num$cal_count==1)
single_cal = subset(cal_dat, cal_dat$Parameter%in%cal_single$Parameter)
single_cal = merge(single_cal, cal_single, all.x = TRUE)
single_cal1 = single_cal%>%mutate(value.corr = value.1+(corrFac*(std-val)))
single_cal1$drift_note = "Corrected for instrument drift"

# Two-point correction
cal_dbl = subset(cal_num, cal_num$cal_count==2)
if(dim(cal_dbl)[1]>0){
double_cal = subset(cal_dat, cal_dat$Parameter%in%cal_dbl$Parameter)
# double_cal = merge(double_cal, cal_dbl, all.x = TRUE)
cal_dbl_wide = cal_dbl%>%pivot_wider(id_cols=Parameter,names_from = std, values_from=c(std, val))

double_cal1 = merge(double_cal, cal_dbl_wide, all.x = TRUE)
double_cal1$low = double_cal1$std_7-(double_cal1$corrFac*(double_cal1$std_7-double_cal1$val_7))
double_cal1$high = double_cal1$std_10-(double_cal1$corrFac*(double_cal1$std_10-double_cal1$val_10))
double_cal1$value.corr = (((double_cal1$value.1-double_cal1$low)/(double_cal1$high-double_cal1$low))*(double_cal1$std_10-double_cal1$std_7))+double_cal1$std_7
double_cal1$drift_note = "Corrected for instrument drift"

drift_corr1 = plyr::rbind.fill(single_cal1, double_cal1)
}else{
  drift_corr1 = single_cal1
}
```

```{r, cal_adjust2, message=FALSE,warning=FALSE, fig.width=12, fig.height=10}
if(!is.na(cal_2$date)){
end_datetime2 = lubridate::mdy_hm(cal_2$date)+lubridate::hours(7)

cal_dat = subset(dat_long1, dat_long1$Date>end_datetime1&dat_long1$Date<end_datetime2&dat_long1$Parameter%in%cal_1$std_val$Parameter)
cal_dat$numTime = as.numeric(cal_dat$Date)
cal_dat$totTime = max(cal_dat$numTime)-min(cal_dat$numTime)
cal_dat$corrFac = (cal_dat$numTime-min(cal_dat$numTime))/cal_dat$totTime

cal_num = cal_2$std_val%>%group_by(Parameter)%>%mutate(cal_count=length(std))

# Single-point correction
cal_single = subset(cal_num, cal_num$cal_count==1)
single_cal = subset(cal_dat, cal_dat$Parameter%in%cal_single$Parameter)
single_cal = merge(single_cal, cal_single, all.x = TRUE)
single_cal1 = single_cal%>%mutate(value.corr = value.1+(corrFac*(std-val)))
single_cal1$drift_note = "Corrected for instrument drift"

# Two-point correction
cal_dbl = subset(cal_num, cal_num$cal_count==2)
if(dim(cal_dbl)[1]>0){
double_cal = subset(cal_dat, cal_dat$Parameter%in%cal_dbl$Parameter)
cal_dbl_wide = cal_dbl%>%pivot_wider(id_cols=Parameter,names_from = std, values_from=c(std, val))

double_cal1 = merge(double_cal, cal_dbl_wide, all.x = TRUE)
double_cal1$low = double_cal1$std_7-(double_cal1$corrFac*(double_cal1$std_7-double_cal1$val_7))
double_cal1$high = double_cal1$std_10-(double_cal1$corrFac*(double_cal1$std_10-double_cal1$val_10))
double_cal1$value.corr = (((double_cal1$value.1-double_cal1$low)/(double_cal1$high-double_cal1$low))*(double_cal1$std_10-double_cal1$std_7))+double_cal1$std_7
double_cal1$drift_note = "Corrected for instrument drift"

drift_corr2 = plyr::rbind.fill(single_cal1, double_cal1)
}else{
  drift_corr2 = single_cal1
}
}else{drift_corr2 = data.frame()}

```

```{r, drift-combine}
drift_corr = plyr::rbind.fill(drift_corr1, drift_corr2)
dat_long2 = merge(dat_long1, drift_corr, all.x = TRUE)
dat_long2$value.2 = ifelse(!is.na(dat_long2$value.corr), dat_long2$value.corr, dat_long2$value.1)
rm(drift_corr, drift_corr_long, drift_corr1, drift_corr2, cal_1, cal_2, cal_dat, cal_dbl, cal_num,cal_single, cal_values, single_cal, single_cal1)
```

## QC Step 3: Flag Non-Real Values
Specify the mininum and maximum real value limits for each parameter.
Apply limits to dataset and convert updated result value to NA if it falls outside of the allowable range.

```{r, nonreal-remove}
limits = data.frame(Parameter=c("Temperature","Specific conductance","pH","DO saturation","DO concentration","Turbidity"), min = c(Temperature[1],Specific_conductance[1],pH[1],DO_saturation[1],DO_conc[1],Turbidity[1]), max=c(Temperature[2],Specific_conductance[2],pH[2],DO_saturation[2],DO_conc[2],Turbidity[2]))

rm(Temperature,Specific_conductance,pH, DO_conc, DO_saturation, Turbidity)

dat_long3 = merge(dat_long2, limits, all.x=TRUE)
dat_long3$value.3 = ifelse(dat_long3$value.2<dat_long3$min|dat_long3$value.2>dat_long3$max,NA,dat_long3$value.2)
dat_long3$ex_value_note = ifelse(is.na(dat_long3$value.3)&!is.na(dat_long3$value.2),"Value Removed - Erroneous",NA)
head(dat_long3[order(dat_long3$ex_value_note),])
```
## QC Step 4: Interpolate gaps of missing values
Specify the frequency of data collection and the maximum gap allowable to interpolate between two points.

### Load interpolation function
```{r, interp_func}
# future addition: interpolation method - linear, polynomial, etc.
source("intGap.R")
# intGap <- function(x,col,by,maxg){
#   byt = paste0(by," mins")
#   names(x)[names(x)==col] = "intv"
#   y = data.frame(Date = seq(min(x$Date),max(x$Date),by=byt))
#   z = merge(x,y,all=TRUE)
#   z = z[order(z$Date),]
#   z$Parameter = unique(x$Parameter)
#   z$units = unique(x$units)
#   z$value.int = zoo::na.approx(z$intv,maxgap = maxg)
#   z$interpolation_note = ifelse(is.na(z$intv)&!is.na(z$value.int),"Interpolated",NA)
#   names(z)[names(z)=="intv"] = col
#   return(z)
# }
```

### Apply interpolation function by parameter
```{r, int_data, message=FALSE}
dat_long4 = dat_long3%>%group_by(Parameter)%>%dplyr::group_map(~intGap(.x,"value.3",by=frequency,maxg=max_gap),.keep=TRUE)%>%plyr::rbind.fill()
names(dat_long4)[names(dat_long4)=="value.int"] = "value.4"
check = nrow(dat_long4)

max_id = max(dat_long4$sampID, na.rm = TRUE)
needid = subset(dat_long4, is.na(dat_long4$sampID))
needid$sampID = seq(max_id+1, max_id+nrow(needid), by=1)

dat_id = subset(dat_long4, !is.na(dat_long4$sampID))
dat_long4 = plyr::rbind.fill(dat_id, needid)

if(!check==nrow(dat_long4))stop("Dataframe dimensions changed when assigning IDs to interpolated values.")
```

## Save and plot data
High frequency dataset is saved in a long format with the file extension .Rdata. This code chunk produces plotly .html plots in the working directory for each parameter, showing the raw data as well as the drift corrected, removed, and interpolated points.
```{r, save_data}
save(dat_long, dat_long4, file = "data_cleaned_v3.Rdata")
```

```{r, all_data_plots, message=FALSE, warning=FALSE,fig.width=12, fig.height=14}
# OG
raw = subset(dat_long4, !is.na(dat_long4$value_raw))
raw$value_plot = raw$value_raw
raw$type = "raw"

# ADJUSTED/FLAGGED
interps = subset(dat_long4, !is.na(dat_long4$interpolation_note))
interps$value_plot = interps$value.4
interps$type = "interpolated"
extremes = subset(dat_long4, !is.na(dat_long4$ex_value_note))
extremes$value_plot = extremes$value.2
extremes$type = "nonreal value"
zeros = subset(dat_long4, !is.na(dat_long4$zero_note))
zeros$value_plot = zeros$value_raw
zeros$type = "suspect zero"

ids = unique(c(interps$sampID, extremes$sampID, zeros$sampID))

# DRIFT
drift = subset(dat_long4, !is.na(dat_long4$drift_note)&!dat_long4$sampID%in%ids)
drift$value_plot = drift$value.2
drift$type = "corrected for drift"

allpdat = plyr::rbind.fill(drift, raw, interps, extremes, zeros)
allpdat$type_fac = factor(allpdat$type, levels = c("raw","suspect zero","nonreal value","corrected for drift", "interpolated"))
allpdat = allpdat[order(allpdat$type_fac),]

g = ggplot2::ggplot(data=allpdat, aes(x=Date,y=value_plot, color=type_fac))+geom_point()+facet_wrap(.~Parameter, ncol=1, scales="free")
g

params = unique(allpdat$Parameter)
for(i in 1:length(params)){
  dat = subset(allpdat, allpdat$Parameter==params[i])
  g = plotly::plot_ly(data=dat,x=~Date,y=~value_plot, name=~type_fac, type="scatter",mode="markers")%>%layout(title = params[i])
  htmlwidgets::saveWidget(g,file=paste0(params[i],"_",sitename,"_QCplot.html"))
}
```

